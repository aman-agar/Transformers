# Transformers
This repo contains code for building the **Transformer** model from scratch. BPE (Byte-Pair Encoding) is used for tokenizing. 
